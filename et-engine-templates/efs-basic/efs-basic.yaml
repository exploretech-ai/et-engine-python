Parameters:
  vfsID:
    Type: String
  BootstrapVersion:
    Type: AWS::SSM::Parameter::Value<String>
    Default: /cdk-bootstrap/hnb659fds/version
    Description: Version of the CDK Bootstrap resources in this environment, automatically retrieved from SSM Parameter Store. [cdk:skip]
Resources:
  ClusterSG2fromEfsBasicStackVFSLambdaSecurityGroup907B6CFC2049386C227F:
    Type: AWS::EC2::SecurityGroupIngress
    Properties:
      Description: from EfsBasicStackVFSLambdaSecurityGroup907B6CFC:2049
      FromPort: 2049
      GroupId: sg-08ad2fb3a42e5ce01
      IpProtocol: tcp
      SourceSecurityGroupId:
        Fn::GetAtt:
          - VFSLambdaSecurityGroupD84993EA
          - GroupId
      ToPort: 2049
    Metadata:
      aws:cdk:path: EfsBasicStack/ClusterSG2/from EfsBasicStackVFSLambdaSecurityGroup907B6CFC:2049
  vfs0804DAB7:
    Type: AWS::EFS::FileSystem
    Properties:
      Encrypted: true
      FileSystemPolicy:
        Statement:
          - Action: elasticfilesystem:*
            Effect: Allow
            Principal:
              AWS: "*"
          - Action:
              - elasticfilesystem:ClientRootAccess
              - elasticfilesystem:ClientWrite
            Condition:
              Bool:
                elasticfilesystem:AccessedViaMountTarget: "true"
            Effect: Allow
            Principal:
              AWS: "*"
        Version: "2012-10-17"
      FileSystemTags:
        - Key: Name
          Value:
            Fn::Join:
              - ""
              - - vfs-
                - Ref: vfsID
    UpdateReplacePolicy: Retain
    DeletionPolicy: Retain
    Metadata:
      aws:cdk:path: EfsBasicStack/vfs/Resource
  vfsEfsMountTargetPrivateSubnet12A54EF59:
    Type: AWS::EFS::MountTarget
    Properties:
      FileSystemId:
        Ref: vfs0804DAB7
      SecurityGroups:
        - sg-08ad2fb3a42e5ce01
      SubnetId: subnet-02dfa489e5a01d330
    Metadata:
      aws:cdk:path: EfsBasicStack/vfs/EfsMountTarget-PrivateSubnet1
  vfsEfsMountTargetPrivateSubnet2E813BC5E:
    Type: AWS::EFS::MountTarget
    Properties:
      FileSystemId:
        Ref: vfs0804DAB7
      SecurityGroups:
        - sg-08ad2fb3a42e5ce01
      SubnetId: subnet-022ee067d2b1ebe0c
    Metadata:
      aws:cdk:path: EfsBasicStack/vfs/EfsMountTarget-PrivateSubnet2
  vfsvfsAccessPointA97EC7A7:
    Type: AWS::EFS::AccessPoint
    Properties:
      AccessPointTags:
        - Key: Name
          Value: EfsBasicStack/vfs/vfsAccessPoint
      FileSystemId:
        Ref: vfs0804DAB7
      PosixUser:
        Gid: "0"
        Uid: "0"
      RootDirectory:
        CreationInfo:
          OwnerGid: "0"
          OwnerUid: "0"
          Permissions: "777"
        Path: /
    Metadata:
      aws:cdk:path: EfsBasicStack/vfs/vfsAccessPoint/Resource
  VFSLambdaServiceRole600D85E0:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Statement:
          - Action: sts:AssumeRole
            Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
        Version: "2012-10-17"
      ManagedPolicyArns:
        - Fn::Join:
            - ""
            - - "arn:"
              - Ref: AWS::Partition
              - :iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
        - Fn::Join:
            - ""
            - - "arn:"
              - Ref: AWS::Partition
              - :iam::aws:policy/service-role/AWSLambdaVPCAccessExecutionRole
    DependsOn:
      - vfsEfsMountTargetPrivateSubnet12A54EF59
      - vfsEfsMountTargetPrivateSubnet2E813BC5E
    Metadata:
      aws:cdk:path: EfsBasicStack/VFSLambda/ServiceRole/Resource
  VFSLambdaServiceRoleDefaultPolicyDCB78257:
    Type: AWS::IAM::Policy
    Properties:
      PolicyDocument:
        Statement:
          - Action: elasticfilesystem:ClientMount
            Condition:
              StringEquals:
                elasticfilesystem:AccessPointArn:
                  Fn::Join:
                    - ""
                    - - arn:aws:elasticfilesystem:us-east-2:734818840861:access-point/
                      - Ref: vfsvfsAccessPointA97EC7A7
            Effect: Allow
            Resource: "*"
          - Action: elasticfilesystem:ClientWrite
            Effect: Allow
            Resource:
              Fn::Join:
                - ""
                - - arn:aws:elasticfilesystem:us-east-2:734818840861:file-system/
                  - Ref: vfs0804DAB7
          - Action: s3:*
            Effect: Allow
            Resource:
              - Fn::GetAtt:
                  - UploadBucketD2C1DA78
                  - Arn
              - Fn::Join:
                  - ""
                  - - Fn::GetAtt:
                        - UploadBucketD2C1DA78
                        - Arn
                    - /*
        Version: "2012-10-17"
      PolicyName: VFSLambdaServiceRoleDefaultPolicyDCB78257
      Roles:
        - Ref: VFSLambdaServiceRole600D85E0
    DependsOn:
      - vfsEfsMountTargetPrivateSubnet12A54EF59
      - vfsEfsMountTargetPrivateSubnet2E813BC5E
    Metadata:
      aws:cdk:path: EfsBasicStack/VFSLambda/ServiceRole/DefaultPolicy/Resource
  VFSLambdaSecurityGroupD84993EA:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Automatic security group for Lambda Function EfsBasicStackVFSLambda7A462EF4
      SecurityGroupEgress:
        - CidrIp: 0.0.0.0/0
          Description: Allow all outbound traffic by default
          IpProtocol: "-1"
      VpcId: vpc-05c602ef885d449bc
    DependsOn:
      - vfsEfsMountTargetPrivateSubnet12A54EF59
      - vfsEfsMountTargetPrivateSubnet2E813BC5E
    Metadata:
      aws:cdk:path: EfsBasicStack/VFSLambda/SecurityGroup/Resource
  VFSLambda5FAABBC2:
    Type: AWS::Lambda::Function
    Properties:
      Code:
        ZipFile: "

          import os

          import base64

          import math

          import json

          import boto3

          import shutil



          def delete(event):


          \    file_path = event['file']

          \    print(f\"file_path={file_path}\")


          \    try:

          \        if os.path.isfile(file_path):

          \            os.remove(file_path)

          \        elif os.path.isdir(file_path):

          \            shutil.rmtree(file_path)

          \        else:

          \            raise OSError('path is neither file nor directory')

          \    except OSError:

          \        return {\"message\": \"couldn't delete the file\", \"statusCode\": 500}

          \    else:

          \        return {\"message\": \"file deletion successful\", \"statusCode\": 200}



          def make_dir(event):

          \    path = event['path']

          \    print(f\"path={path}\")


          \    try:

          \        os.mkdir(path)

          \    except OSError:

          \        return {\"message\": \"couldn't create the directory\", \"statusCode\": 500}

          \    else:

          \        return {\"message\": \"directory creation successful\", \"statusCode\": 200}



          def upload(event):

          \    print(\"UPLOAD REQUESTED\")

          \    print(event)


          \    s3_bucket = event['Records'][0]['s3']['bucket']['name']

          \    s3_key = event['Records'][0]['s3']['object']['key']


          \    print('bucket: ', s3_bucket)

          \    print('key: ', s3_key)


          \    # Set the download path in the /tmp directory

          \    # download_path = '/tmp/' + os.path.basename(s3_key)

          \    destination_path = '/mnt/efs/' + s3_key[2:]

          \    # print('local path: ', download_path)


          \    # Create an S3 client

          \    s3_client = boto3.client('s3')


          \    try:

          \        # Download the file from S3

          \        print('Dowloading...')

          \        s3_client.download_file(s3_bucket, s3_key, destination_path)

          \        print(f\"success\")

          \        return {'message': 'successfully transfered file to EFS', 'statusCode': 200}

          \    except Exception as e:

          \        print(f\"Error downloading file: {str(e)}\")

          \        return {'message': 'failed while downloading file to EFS', 'statusCode': 500}


          \         \ 

          def download(event):


          \    print('DOWNlOAD REQUESTED')


          \    try:

          \        key = event['key']

          \        prefix = event['prefix']

          \        bucket_name = event['vfs']


          \        print(f\"key: {key}\")

          \        print(f\"prefix: {prefix}\")

          \        print(f\"bucket_name: {bucket_name}\")


          \        file = prefix + key


          \        # Copy file to s3

          \        s3_client = boto3.client('s3')

          \        s3_client.upload_file(file, bucket_name, key)


          \        # Create presigned GET

          \        presigned_url = s3_client.generate_presigned_url(

          \            'get_object',

          \            Params={'Bucket': bucket_name, 'Key': key},

          \            ExpiresIn=60

          \        )

          \        return {'presigned_url': presigned_url, 'statusCode': 200}

          \    except KeyError as e:

          \        return {'presigned_url': 'KEY_ERROR', 'statusCode': 500}

          \    except Exception as e:

          \        print(f\"Exception: {e}\")

          \        return {'presigned_url': 'UNKNOWN EXCEPTION', 'statusCode': 500}



          def list(path):

          \   \ 

          \    try:

          \        dir_items = []

          \        file_items = []

          \        for (dirpath, dirnames, filenames) in os.walk(path):

          \            dir_items.extend(dirnames)

          \            file_items.extend(filenames)

          \            break

          \        print(\"directories: \", dir_items)

          \        print(\"files: \", file_items)


          \    except Exception as error:

          \        print(error)

          \        return {\"message\": \"unable to list files\", \"statusCode\": 500}

          \    else:

          \        return {\"path\": path, \"directories\": dir_items, \"files\": file_items, \"statusCode\": 200}



          def handler(event, _context):

          \    try:

          \        if \"Records\" in event:

          \            operation_type = \"upload\"

          \            path = None

          \        else:

          \            operation_type = event['operation']

          \           \ 

          \    except KeyError:

          \        return {\"message\": \"missing required parameter: operation\", \"statusCode\": 400}

          \    else:

          \        print(\"Operation Type: \", operation_type)

          \        if operation_type == 'upload':

          \            upload_result = upload(event)

          \            return upload_result

          \        if operation_type == 'list':

          \            path = event['path']

          \            list_result = list(path)

          \            return list_result

          \        if operation_type == 'delete':

          \            delete_result = delete(event)

          \            return delete_result

          \        if operation_type == 'mkdir':

          \            make_dir_result = make_dir(event)

          \            return make_dir_result

          \        if operation_type == 'download':

          \            download_result = download(event)

          \            return download_result

          \        "
      FileSystemConfigs:
        - Arn:
            Fn::Join:
              - ""
              - - arn:aws:elasticfilesystem:us-east-2:734818840861:access-point/
                - Ref: vfsvfsAccessPointA97EC7A7
          LocalMountPath: /mnt/efs
      FunctionName:
        Fn::Join:
          - ""
          - - vfs-
            - Ref: vfsID
      Handler: index.handler
      Role:
        Fn::GetAtt:
          - VFSLambdaServiceRole600D85E0
          - Arn
      Runtime: python3.8
      Timeout: 900
      VpcConfig:
        SecurityGroupIds:
          - Fn::GetAtt:
              - VFSLambdaSecurityGroupD84993EA
              - GroupId
        SubnetIds:
          - subnet-02dfa489e5a01d330
          - subnet-022ee067d2b1ebe0c
    DependsOn:
      - ClusterSG2fromEfsBasicStackVFSLambdaSecurityGroup907B6CFC2049386C227F
      - vfsEfsMountTargetPrivateSubnet12A54EF59
      - vfsEfsMountTargetPrivateSubnet2E813BC5E
      - VFSLambdaServiceRoleDefaultPolicyDCB78257
      - VFSLambdaServiceRole600D85E0
    Metadata:
      aws:cdk:path: EfsBasicStack/VFSLambda/Resource
  UploadBucketD2C1DA78:
    Type: AWS::S3::Bucket
    Properties:
      BucketName:
        Fn::Join:
          - ""
          - - vfs-
            - Ref: vfsID
      CorsConfiguration:
        CorsRules:
          - AllowedHeaders:
              - "*"
            AllowedMethods:
              - PUT
              - POST
              - GET
              - DELETE
              - HEAD
            AllowedOrigins:
              - "*"
            MaxAge: 3000
      LifecycleConfiguration:
        Rules:
          - ExpirationInDays: 1
            Status: Enabled
      Tags:
        - Key: aws-cdk:auto-delete-objects
          Value: "true"
    UpdateReplacePolicy: Delete
    DeletionPolicy: Delete
    Metadata:
      aws:cdk:path: EfsBasicStack/UploadBucket/Resource
  UploadBucketPolicy180778F4:
    Type: AWS::S3::BucketPolicy
    Properties:
      Bucket:
        Ref: UploadBucketD2C1DA78
      PolicyDocument:
        Statement:
          - Action:
              - s3:DeleteObject*
              - s3:GetBucket*
              - s3:List*
              - s3:PutBucketPolicy
            Effect: Allow
            Principal:
              AWS:
                Fn::GetAtt:
                  - CustomS3AutoDeleteObjectsCustomResourceProviderRole3B1BD092
                  - Arn
            Resource:
              - Fn::GetAtt:
                  - UploadBucketD2C1DA78
                  - Arn
              - Fn::Join:
                  - ""
                  - - Fn::GetAtt:
                        - UploadBucketD2C1DA78
                        - Arn
                    - /*
        Version: "2012-10-17"
    Metadata:
      aws:cdk:path: EfsBasicStack/UploadBucket/Policy/Resource
  UploadBucketAutoDeleteObjectsCustomResource36B44E3D:
    Type: Custom::S3AutoDeleteObjects
    Properties:
      ServiceToken:
        Fn::GetAtt:
          - CustomS3AutoDeleteObjectsCustomResourceProviderHandler9D90184F
          - Arn
      BucketName:
        Ref: UploadBucketD2C1DA78
    DependsOn:
      - UploadBucketPolicy180778F4
    UpdateReplacePolicy: Delete
    DeletionPolicy: Delete
    Metadata:
      aws:cdk:path: EfsBasicStack/UploadBucket/AutoDeleteObjectsCustomResource/Default
  UploadBucketNotifications5E120ADB:
    Type: Custom::S3BucketNotifications
    Properties:
      ServiceToken:
        Fn::GetAtt:
          - BucketNotificationsHandler050a0587b7544547bf325f094a3db8347ECC3691
          - Arn
      BucketName:
        Ref: UploadBucketD2C1DA78
      NotificationConfiguration:
        LambdaFunctionConfigurations:
          - Events:
              - s3:ObjectCreated:*
            Filter:
              Key:
                FilterRules:
                  - Name: prefix
                    Value: ./
            LambdaFunctionArn:
              Fn::GetAtt:
                - VFSLambda5FAABBC2
                - Arn
      Managed: true
    DependsOn:
      - UploadBucketAllowBucketNotificationsToEfsBasicStackVFSLambda7A462EF437A72EF7
    Metadata:
      aws:cdk:path: EfsBasicStack/UploadBucket/Notifications/Resource
  UploadBucketAllowBucketNotificationsToEfsBasicStackVFSLambda7A462EF437A72EF7:
    Type: AWS::Lambda::Permission
    Properties:
      Action: lambda:InvokeFunction
      FunctionName:
        Fn::GetAtt:
          - VFSLambda5FAABBC2
          - Arn
      Principal: s3.amazonaws.com
      SourceAccount: "734818840861"
      SourceArn:
        Fn::GetAtt:
          - UploadBucketD2C1DA78
          - Arn
    Metadata:
      aws:cdk:path: EfsBasicStack/UploadBucket/AllowBucketNotificationsToEfsBasicStackVFSLambda7A462EF4
  CustomS3AutoDeleteObjectsCustomResourceProviderRole3B1BD092:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Action: sts:AssumeRole
            Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
      ManagedPolicyArns:
        - Fn::Sub: arn:${AWS::Partition}:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
    Metadata:
      aws:cdk:path: EfsBasicStack/Custom::S3AutoDeleteObjectsCustomResourceProvider/Role
  CustomS3AutoDeleteObjectsCustomResourceProviderHandler9D90184F:
    Type: AWS::Lambda::Function
    Properties:
      Code:
        S3Bucket: cdk-hnb659fds-assets-734818840861-us-east-2
        S3Key: b7f33614a69548d6bafe224d751a7ef238cde19097415e553fe8b63a4c8fd8a6.zip
      Timeout: 900
      MemorySize: 128
      Handler: index.handler
      Role:
        Fn::GetAtt:
          - CustomS3AutoDeleteObjectsCustomResourceProviderRole3B1BD092
          - Arn
      Runtime: nodejs18.x
      Description:
        Fn::Join:
          - ""
          - - "Lambda function for auto-deleting objects in "
            - Ref: UploadBucketD2C1DA78
            - " S3 bucket."
    DependsOn:
      - CustomS3AutoDeleteObjectsCustomResourceProviderRole3B1BD092
    Metadata:
      aws:cdk:path: EfsBasicStack/Custom::S3AutoDeleteObjectsCustomResourceProvider/Handler
      aws:asset:path: asset.b7f33614a69548d6bafe224d751a7ef238cde19097415e553fe8b63a4c8fd8a6
      aws:asset:property: Code
  BucketNotificationsHandler050a0587b7544547bf325f094a3db834RoleB6FB88EC:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Statement:
          - Action: sts:AssumeRole
            Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
        Version: "2012-10-17"
      ManagedPolicyArns:
        - Fn::Join:
            - ""
            - - "arn:"
              - Ref: AWS::Partition
              - :iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
    Metadata:
      aws:cdk:path: EfsBasicStack/BucketNotificationsHandler050a0587b7544547bf325f094a3db834/Role/Resource
  BucketNotificationsHandler050a0587b7544547bf325f094a3db834RoleDefaultPolicy2CF63D36:
    Type: AWS::IAM::Policy
    Properties:
      PolicyDocument:
        Statement:
          - Action: s3:PutBucketNotification
            Effect: Allow
            Resource: "*"
        Version: "2012-10-17"
      PolicyName: BucketNotificationsHandler050a0587b7544547bf325f094a3db834RoleDefaultPolicy2CF63D36
      Roles:
        - Ref: BucketNotificationsHandler050a0587b7544547bf325f094a3db834RoleB6FB88EC
    Metadata:
      aws:cdk:path: EfsBasicStack/BucketNotificationsHandler050a0587b7544547bf325f094a3db834/Role/DefaultPolicy/Resource
  BucketNotificationsHandler050a0587b7544547bf325f094a3db8347ECC3691:
    Type: AWS::Lambda::Function
    Properties:
      Description: AWS CloudFormation handler for "Custom::S3BucketNotifications" resources (@aws-cdk/aws-s3)
      Code:
        ZipFile: |
          import boto3  # type: ignore
          import json
          import logging
          import urllib.request

          s3 = boto3.client("s3")

          EVENTBRIDGE_CONFIGURATION = 'EventBridgeConfiguration'
          CONFIGURATION_TYPES = ["TopicConfigurations", "QueueConfigurations", "LambdaFunctionConfigurations"]

          def handler(event: dict, context):
            response_status = "SUCCESS"
            error_message = ""
            try:
              props = event["ResourceProperties"]
              notification_configuration = props["NotificationConfiguration"]
              managed = props.get('Managed', 'true').lower() == 'true'
              stack_id = event['StackId']
              old = event.get("OldResourceProperties", {}).get("NotificationConfiguration", {})
              if managed:
                config = handle_managed(event["RequestType"], notification_configuration)
              else:
                config = handle_unmanaged(props["BucketName"], stack_id, event["RequestType"], notification_configuration, old)
              s3.put_bucket_notification_configuration(Bucket=props["BucketName"], NotificationConfiguration=config)
            except Exception as e:
              logging.exception("Failed to put bucket notification configuration")
              response_status = "FAILED"
              error_message = f"Error: {str(e)}. "
            finally:
              submit_response(event, context, response_status, error_message)

          def handle_managed(request_type, notification_configuration):
            if request_type == 'Delete':
              return {}
            return notification_configuration

          def handle_unmanaged(bucket, stack_id, request_type, notification_configuration, old):
            def with_id(n):
              n['Id'] = f"{stack_id}-{hash(json.dumps(n, sort_keys=True))}"
              return n

            external_notifications = {}
            existing_notifications = s3.get_bucket_notification_configuration(Bucket=bucket)
            for t in CONFIGURATION_TYPES:
              if request_type == 'Update':
                  ids = [with_id(n) for n in old.get(t, [])]
                  old_incoming_ids = [n['Id'] for n in ids]
                  external_notifications[t] = [n for n in existing_notifications.get(t, []) if not n['Id'] in old_incoming_ids]
              elif request_type == 'Create':
                  external_notifications[t] = [n for n in existing_notifications.get(t, [])]
            if EVENTBRIDGE_CONFIGURATION in existing_notifications:
              external_notifications[EVENTBRIDGE_CONFIGURATION] = existing_notifications[EVENTBRIDGE_CONFIGURATION]

            if request_type == 'Delete':
              return external_notifications

            notifications = {}
            for t in CONFIGURATION_TYPES:
              external = external_notifications.get(t, [])
              incoming = [with_id(n) for n in notification_configuration.get(t, [])]
              notifications[t] = external + incoming

            if EVENTBRIDGE_CONFIGURATION in notification_configuration:
              notifications[EVENTBRIDGE_CONFIGURATION] = notification_configuration[EVENTBRIDGE_CONFIGURATION]
            elif EVENTBRIDGE_CONFIGURATION in external_notifications:
              notifications[EVENTBRIDGE_CONFIGURATION] = external_notifications[EVENTBRIDGE_CONFIGURATION]

            return notifications

          def submit_response(event: dict, context, response_status: str, error_message: str):
            response_body = json.dumps(
              {
                "Status": response_status,
                "Reason": f"{error_message}See the details in CloudWatch Log Stream: {context.log_stream_name}",
                "PhysicalResourceId": event.get("PhysicalResourceId") or event["LogicalResourceId"],
                "StackId": event["StackId"],
                "RequestId": event["RequestId"],
                "LogicalResourceId": event["LogicalResourceId"],
                "NoEcho": False,
              }
            ).encode("utf-8")
            headers = {"content-type": "", "content-length": str(len(response_body))}
            try:
              req = urllib.request.Request(url=event["ResponseURL"], headers=headers, data=response_body, method="PUT")
              with urllib.request.urlopen(req) as response:
                print(response.read().decode("utf-8"))
              print("Status code: " + response.reason)
            except Exception as e:
                print("send(..) failed executing request.urlopen(..): " + str(e))
      Handler: index.handler
      Role:
        Fn::GetAtt:
          - BucketNotificationsHandler050a0587b7544547bf325f094a3db834RoleB6FB88EC
          - Arn
      Runtime: python3.9
      Timeout: 300
    DependsOn:
      - BucketNotificationsHandler050a0587b7544547bf325f094a3db834RoleDefaultPolicy2CF63D36
      - BucketNotificationsHandler050a0587b7544547bf325f094a3db834RoleB6FB88EC
    Metadata:
      aws:cdk:path: EfsBasicStack/BucketNotificationsHandler050a0587b7544547bf325f094a3db834/Resource
  CDKMetadata:
    Type: AWS::CDK::Metadata
    Properties:
      Analytics: v2:deflate64:H4sIAAAAAAAA/11QUU/DIBj8LXunaLtEn7clGh+MpPXdMPqt+2yBhQ80DeG/SzszW5/ujjuOcBUvqwd+v5HfVKi2LwY88th4qXp2OBkhndTgwbEayAangOXgRwRV8Zj9BlRw6MdnZ8PlxXQOiNjqkP1PJQYn4vEJB2hG8qCnxFq92mD8u3QdeLZTKncKi8ZP1kImNkh9bGXuCkZ5tGZuWnABTiNRVomh1DzWdoDJmFHYAdU452aWGG153AfVw/zUL7vCX3ipU2KHQN7q2zpT+Y2vLOHsF7bg9pKA7YjA55U7NN105y34S8g/EqM/W3O35WXJHzefhFi4vAVq4PUVfwBqqAGksAEAAA==
    Metadata:
      aws:cdk:path: EfsBasicStack/CDKMetadata/Default
Outputs:
  FileSystemId:
    Value:
      Ref: vfs0804DAB7
  AccessPointId:
    Value:
      Ref: vfsvfsAccessPointA97EC7A7
Rules:
  CheckBootstrapVersion:
    Assertions:
      - Assert:
          Fn::Not:
            - Fn::Contains:
                - - "1"
                  - "2"
                  - "3"
                  - "4"
                  - "5"
                - Ref: BootstrapVersion
        AssertDescription: CDK bootstrap stack version 6 required. Please run 'cdk bootstrap' with a recent version of the CDK CLI.

